{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Data\n",
    "For speed, we will use downsampled data.\n",
    "You can use any gene fast file with this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:37.898347700Z",
     "start_time": "2024-06-18T14:35:36.713457Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:39.030393700Z",
     "start_time": "2024-06-18T14:35:37.898347700Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:44.685651900Z",
     "start_time": "2024-06-18T14:35:39.030393700Z"
    }
   },
   "outputs": [],
   "source": [
    "! pip install numpy==1.23.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:45.899122700Z",
     "start_time": "2024-06-18T14:35:44.682651800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ryan\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (1.38.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     -------------------------------------- 895.9/895.9 kB 5.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (4.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB ? eta 0:00:00\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (63.4.1)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (1.23.4)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 8.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "     ---------------------------------------- 26.4/26.4 MB 9.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ryan\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, tensorflow-io-gcs-filesystem, protobuf, keras-preprocessing, gast\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.1.21\n",
      "    Uninstalling flatbuffers-23.1.21:\n",
      "      Successfully uninstalled flatbuffers-23.1.21\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "  Attempting uninstall: gast\n",
      "    Found existing installation: gast 0.5.3\n",
      "    Uninstalling gast-0.5.3:\n",
      "      Successfully uninstalled gast-0.5.3\n",
      "Successfully installed flatbuffers-1.12 gast-0.4.0 keras-preprocessing-1.1.2 libclang-18.1.1 protobuf-3.19.6 tensorflow-io-gcs-filesystem-0.31.0\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:51:17.736903400Z",
     "start_time": "2024-06-18T14:51:16.520981200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:48:50.527718100Z",
     "start_time": "2024-06-18T14:48:50.464075600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from Bio import SeqIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Disable TensorFlow v2 behavior\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "# Enable plotting in a separate window\n",
    "%matplotlib qt\n",
    "\n",
    "# Function to convert FASTA file to DataFrame\n",
    "def fasta2df(infile):\n",
    "    records = SeqIO.parse(infile, 'fasta')\n",
    "    seqList = []\n",
    "    for record in records:\n",
    "        desp = record.description\n",
    "        seq = str(record.seq).upper()  # Convert the sequence directly to a string and make it uppercase\n",
    "        seqList.append([desp] + [seq])\n",
    "    seq_df = pd.DataFrame(seqList, columns=['strainName', 'seq'])\n",
    "    return seq_df\n",
    "\n",
    "# Load FASTA file and convert to DataFrame\n",
    "df = fasta2df(\"data/alternative_splicing_human_10541.fasta\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:49.160549500Z",
     "start_time": "2024-06-18T14:35:49.156057600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract sequences from the DataFrame into a list (corpus)\n",
    "corpus = list(df['seq'])\n",
    "\n",
    "# Print the first 10 sequences from the corpus\n",
    "print(corpus[:10])\n",
    "\n",
    "# Print the total number of sequences in the corpus\n",
    "print(len(corpus))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:49.164185500Z",
     "start_time": "2024-06-18T14:35:49.161549400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define base mapping dictionaries for encoding and decoding\n",
    "__mapping = {\"A\": 8, \"C\": 4, \"G\": 2, \"T\": 1, \"N\": 15, \"E\": 0}\n",
    "__rmapping = {8: \"A\", 4: \"C\", 2: \"G\", 1: \"T\", 15: \"N\", 0: \"E\"}\n",
    "\n",
    "# Define the base size for encoding\n",
    "base_size = 2**8\n",
    "\n",
    "# Function to encode a DNA sequence into an integer\n",
    "def encode_sequence(sequence):\n",
    "    val = 0\n",
    "    for i, base in enumerate(sequence):\n",
    "        print(base)\n",
    "        val += __mapping[base] * (2**8**i)\n",
    "    return val\n",
    "\n",
    "# Function to decode an integer back into a DNA sequence\n",
    "def decode_sequence(val):\n",
    "    import math\n",
    "\n",
    "    sequence = \"\"\n",
    "    n = math.floor(math.log(val) / math.log(base_size))\n",
    "\n",
    "    while val > 0:\n",
    "        next_layer = val % base_size**n\n",
    "        sequence = str(__rmapping[int((val - next_layer) / base_size**n)]) + sequence\n",
    "        n -= 1\n",
    "        val = next_layer\n",
    "\n",
    "    return sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsample: A Larger n Results in a Longer Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:49.167575200Z",
     "start_time": "2024-06-18T14:35:49.163561600Z"
    }
   },
   "outputs": [],
   "source": [
    "n=2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:49.170182400Z",
     "start_time": "2024-06-18T14:35:49.166575100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to remove null amino acids from sequences\n",
    "def remove_null_AA(corpus_dna_new):\n",
    "    null_AAs = ['_', '_', \"_\", \"_\", \"_\", \"_\", \"_\"]\n",
    "    results = []\n",
    "    print(len(corpus_dna_new))\n",
    "    for text in corpus_dna_new:\n",
    "        tmp = list(text)\n",
    "        for null_AA in null_AAs:\n",
    "            if null_AA in tmp:\n",
    "                tmp.remove(null_AA)\n",
    "        results.append(\"\".join(tmp))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:49.177093100Z",
     "start_time": "2024-06-18T14:35:49.170182400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to extract unique amino acids from sequences\n",
    "def amin(corpus_dna_new):\n",
    "    amino_acids = []\n",
    "    for text in corpus_dna_new:\n",
    "        for AA in list(text):\n",
    "            amino_acids.append(AA)\n",
    "    \n",
    "    amino_acids = set(amino_acids)\n",
    "    return list(amino_acids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:49.428200100Z",
     "start_time": "2024-06-18T14:35:49.191097600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract and display unique amino acids from the corpus\n",
    "amino_acids = amin(corpus)\n",
    "amino_acids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:35:49.431483100Z",
     "start_time": "2024-06-18T14:35:49.428200100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert amino acids to integers and generate training data\n",
    "def data_out(amino_acids, corpus_dna_new):\n",
    "    AA2int = {}\n",
    "\n",
    "    # Create a mapping from amino acids to integers\n",
    "    for i, AA in enumerate(amino_acids):\n",
    "        AA2int[AA] = i\n",
    "\n",
    "    sentences = []\n",
    "    for sentence in corpus_dna_new:\n",
    "        sentences.append(list(sentence))\n",
    "\n",
    "    WINDOW_SIZE = 2\n",
    "\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        for idx, AA in enumerate(sentence):\n",
    "            for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1]:\n",
    "                if neighbor != AA:\n",
    "                    data.append([AA, neighbor])\n",
    "    \n",
    "    return AA2int, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:04.986664900Z",
     "start_time": "2024-06-18T14:35:49.430482900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the amino acid to integer mapping and training data\n",
    "AA2int, data = data_out(amino_acids, corpus)\n",
    "\n",
    "# Display the AA to integer mapping and training data\n",
    "print(AA2int)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:05.230558200Z",
     "start_time": "2024-06-18T14:36:05.229562Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert data into a pandas DataFrame\n",
    "def pandify(data):\n",
    "    df = pd.DataFrame(data, columns=['input', 'label'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-18T14:36:05.230558200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the data into a pandas DataFrame\n",
    "df = pandify(data)\n",
    "\n",
    "# Downsample the DataFrame to the first 'n' rows\n",
    "df_downsampled = df.head(n)\n",
    "\n",
    "# Display the downsampled DataFrame\n",
    "df_downsampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-18T14:36:05.232561900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert numbers to one hot vectors\n",
    "def to_one_hot_encoding(data_point_index, amino_acids):\n",
    "    ONE_HOT_DIM = len(amino_acids)\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[data_point_index] = 1\n",
    "    return one_hot_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-18T14:36:05.233561900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to define the computational graph for training the model\n",
    "def define_graph(AA2int, amino_acids, df):\n",
    "    ONE_HOT_DIM = len(amino_acids)\n",
    "    X = []  # input amino acid\n",
    "    Y = []  # target amino acid\n",
    "\n",
    "    for x, y in zip(df['input'], df['label']):\n",
    "        X.append(to_one_hot_encoding(AA2int[x], amino_acids))\n",
    "        Y.append(to_one_hot_encoding(AA2int[y], amino_acids))\n",
    "\n",
    "    # Convert them to numpy arrays\n",
    "    X_train = np.asarray(X)\n",
    "    Y_train = np.asarray(Y)\n",
    "\n",
    "    # Placeholders for X_train and Y_train\n",
    "    x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "    y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "    # AA embedding will be 3 dimension for 3D visualization\n",
    "    EMBEDDING_DIM = 3\n",
    "\n",
    "    # Hidden layer: which represents AA vector eventually\n",
    "    W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "    b1 = tf.Variable(tf.random_normal([1]))  # Bias\n",
    "    hidden_layer = tf.add(tf.matmul(x, W1), b1)\n",
    "\n",
    "    # Output layer\n",
    "    W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "    b2 = tf.Variable(tf.random_normal([1]))\n",
    "    prediction = tf.nn.softmax(tf.add(tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "    # Loss function: cross entropy\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
    "\n",
    "    # Training operation\n",
    "    train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "    \n",
    "    return X_train, Y_train, x, y_label, W1, b1, W2, b2, loss, train_op\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:05.244044900Z",
     "start_time": "2024-06-18T14:36:05.234562400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the computational graph using the downsampled DataFrame\n",
    "X_train_downsampled, Y_train_downsampled, x_downsampled, y_label_downsampled, W1_downsampled, b1_downsampled, W2_downsampled, b2_downsampled, loss_downsampled, train_op_downsampled = define_graph(AA2int, amino_acids, df_downsampled)\n",
    "\n",
    "# Display the shapes of the training data arrays\n",
    "print(f\"X_train_downsampled shape: {X_train_downsampled.shape}\")\n",
    "print(f\"Y_train_downsampled shape: {Y_train_downsampled.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.633377400Z",
     "start_time": "2024-06-18T14:36:05.244044900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize and run the TensorFlow session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Training loop\n",
    "iteration = 20000\n",
    "for i in range(iteration):\n",
    "    # Input is X_train which is one hot encoded AA\n",
    "    # Label is Y_train which is one hot encoded neighbor AA\n",
    "    sess.run(train_op_downsampled, feed_dict={x_downsampled: X_train_downsampled, y_label_downsampled: Y_train_downsampled})\n",
    "    if i % 3000 == 0:\n",
    "        loss_value = sess.run(loss_downsampled, feed_dict={x_downsampled: X_train_downsampled, y_label_downsampled: Y_train_downsampled})\n",
    "        print(f'Iteration {i}, loss: {loss_value}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.641341300Z",
     "start_time": "2024-06-18T14:36:12.633377400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now the hidden layer (W1 + b1) is actually the AA lookup table\n",
    "vectors_downsampled = sess.run(W1_downsampled + b1_downsampled)\n",
    "\n",
    "# Optionally, print the vectors\n",
    "# print(vectors_downsampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AA vector in table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.646945700Z",
     "start_time": "2024-06-18T14:36:12.641341300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with the amino acid vectors\n",
    "w2v_df_downsampled = pd.DataFrame(vectors_downsampled, columns=['x1', 'x2', 'x3'])\n",
    "w2v_df_downsampled['AA'] = amino_acids\n",
    "w2v_df_downsampled = w2v_df_downsampled[['AA', 'x1', 'x2', 'x3']]\n",
    "\n",
    "# Optionally, display the DataFrame\n",
    "# w2v_df_downsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.653280700Z",
     "start_time": "2024-06-18T14:36:12.646945700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop rows where the amino acid is \"_\"\n",
    "w2v_df_downsampled.drop(w2v_df_downsampled[w2v_df_downsampled['AA'] == \"_\"].index, inplace=True)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "w2v_df_downsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.656644200Z",
     "start_time": "2024-06-18T14:36:12.653280700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a list of amino acids from the cleaned DataFrame\n",
    "AA_lst_downsampled = list(w2v_df_downsampled['AA'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.659658500Z",
     "start_time": "2024-06-18T14:36:12.656644200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a color mapping for amino acids\n",
    "color_mp = {\n",
    "    'D': 'b', 'E': 'b',   # Blue for acidic amino acids\n",
    "    'R': 'r', 'K': 'r', 'H': 'r',  # Red for basic amino acids\n",
    "    'N': 'y', 'Q': 'y', 'S': 'y', 'T': 'y', 'Y': 'y',  # Yellow for polar uncharged amino acids\n",
    "    'A': 'g', 'V': 'g', 'L': 'g', 'I': 'g', 'P': 'g', 'F': 'g', 'M': 'g', 'W': 'g', 'C': 'g', 'G': 'g'  # Green for nonpolar amino acids\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.662149100Z",
     "start_time": "2024-06-18T14:36:12.659658500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate a list of color codes for each amino acid in the list\n",
    "color_code_downsampled = []\n",
    "for i, elt in enumerate(AA_lst_downsampled):\n",
    "    color_code_downsampled.append(color_mp.get(elt, 'w'))  # Default to 'w' (white) if amino acid not found in color_mp\n",
    "AA_lst_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.680069800Z",
     "start_time": "2024-06-18T14:36:12.662149100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a zip object with amino acid labels and their corresponding vectors\n",
    "z_data_downsampled = zip(w2v_df_downsampled['AA'], w2v_df_downsampled['x1'], w2v_df_downsampled['x2'])\n",
    "\n",
    "# Convert to a list if you need to view or iterate multiple times\n",
    "z_data_downsampled = list(z_data_downsampled)\n",
    "\n",
    "# Display the zipped data\n",
    "z_data_downsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:36:12.681072700Z",
     "start_time": "2024-06-18T14:36:12.666159900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterate through the zipped data and print the amino acids and their corresponding vectors\n",
    "for (AA_downsampled, x1_downsampled, x2_downsampled) in z_data_downsampled:\n",
    "    print(AA_downsampled, x1_downsampled, x2_downsampled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T14:51:25.268140600Z",
     "start_time": "2024-06-18T14:51:25.240846500Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.gca(projection='3d')\n",
    "\n",
    "for i in range(len(w2v_df_downsampled)):\n",
    "    sc = ax.scatter(w2v_df_downsampled['x1'][i], w2v_df_downsampled['x2'][i], w2v_df_downsampled['x3'][i], c=color_code_downsampled[i], marker=r\"$ {} $\".format(AA_lst_downsampled[i]), s=100)\n",
    "    \n",
    "# for i in range(len(w2v_df_downsampled)):\n",
    "#     sc = ax.scatter(w2v_df_downsampled['x1'][i], w2v_df_downsampled['x2'][i], w2v_df_downsampled['x3'][i], c=color_code_downsampled[i], marker=r\"$ {} $\".format(AA_lst_downsampled[i]), s=100, cmap=\"Spectral\")    \n",
    "\n",
    "# plt.colorbar(sc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-06-18T14:36:13.200814100Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
